{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/benchmarks-artifacts/travel-db/travel2.sqlite\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"travel.db\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded and saved as travel.db\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def update_dates(file):\n",
    "    conn = sqlite3.connect(file)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    tables = pd.read_sql(\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table';\", conn\n",
    "    ).name.tolist()\n",
    "    tdf = {}\n",
    "    for t in tables:\n",
    "        tdf[t] = pd.read_sql(f\"SELECT * from {t}\", conn)\n",
    "\n",
    "    example_time = pd.to_datetime(\n",
    "        tdf[\"flights\"][\"actual_departure\"].replace(\"\\\\N\", pd.NaT)\n",
    "    ).max()\n",
    "    current_time = pd.to_datetime(\"now\").tz_localize(example_time.tz)\n",
    "    time_diff = current_time - example_time\n",
    "\n",
    "    tdf[\"bookings\"][\"book_date\"] = (\n",
    "        pd.to_datetime(tdf[\"bookings\"][\"book_date\"].replace(\"\\\\N\", pd.NaT), utc=True)\n",
    "        + time_diff\n",
    "    )\n",
    "\n",
    "    datetime_columns = [\n",
    "        \"scheduled_departure\",\n",
    "        \"scheduled_arrival\",\n",
    "        \"actual_departure\",\n",
    "        \"actual_arrival\",\n",
    "    ]\n",
    "    for column in datetime_columns:\n",
    "        tdf[\"flights\"][column] = (\n",
    "            pd.to_datetime(tdf[\"flights\"][column].replace(\"\\\\N\", pd.NaT)) + time_diff\n",
    "        )\n",
    "\n",
    "    for table_name, df in tdf.items():\n",
    "        df.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "    del df\n",
    "    del tdf\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    return file\n",
    "\n",
    "local_file = 'travel.db'\n",
    "\n",
    "db = update_dates(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(\"travel.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    print(f\"\\nTable: {table_name}\")\n",
    "\n",
    "    query = f\"SELECT * FROM {table_name} LIMIT 10;\"\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "    row_count = cursor.fetchone()[0]  # Get the count value\n",
    "\n",
    "    print(f\"Table: {table_name} | Row Count: {row_count}\")\n",
    "    df = pd.read_sql(query, conn)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"No data available.\")\n",
    "    else:\n",
    "        print(df.to_markdown(index=False)) \n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "\n",
    "# Establish SQLite connection\n",
    "sqlite_conn = sqlite3.connect(\"travel.db\")\n",
    "sqlite_cursor = sqlite_conn.cursor()\n",
    "\n",
    "# Establish PostgreSQL connection\n",
    "pg_conn = psycopg2.connect(\n",
    "    dbname=os.environ[\"DB_NAME\"],\n",
    "    user=os.environ[\"DB_USER\"],\n",
    "    password=os.environ[\"DB_PASSWORD\"],\n",
    "    host=os.environ[\"DB_HOST\"],\n",
    "    port=os.environ[\"DB_PORT\"]\n",
    ")\n",
    "pg_cursor = pg_conn.cursor()\n",
    "\n",
    "# Get all table names from SQLite\n",
    "sqlite_cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = [table[0] for table in sqlite_cursor.fetchall()]\n",
    "\n",
    "# Batch size for inserts\n",
    "BATCH_SIZE = 5000  \n",
    "\n",
    "for table_name in tables:\n",
    "    print(f\"ðŸ”„ Migrating table: {table_name}\")\n",
    "\n",
    "    # Get column names and types from SQLite\n",
    "    sqlite_cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    columns = sqlite_cursor.fetchall()\n",
    "    column_names = [column[1] for column in columns]\n",
    "\n",
    "    # Create the table in PostgreSQL\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "    create_table_query += \", \".join(\n",
    "        f\"{column[1]} {column[2].replace('NVARCHAR', 'VARCHAR').replace('DATETIME', 'TIMESTAMP')}\"\n",
    "        for column in columns\n",
    "    )\n",
    "    create_table_query += \");\"\n",
    "    pg_cursor.execute(create_table_query)\n",
    "    \n",
    "    # Count total rows\n",
    "    sqlite_cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "    total_rows = sqlite_cursor.fetchone()[0]\n",
    "    print(f\"ðŸ“Š Total rows in {table_name}: {total_rows}\")\n",
    "\n",
    "    # Fetch and insert data in batches\n",
    "    offset = 0\n",
    "    while True:\n",
    "        sqlite_cursor.execute(f\"SELECT * FROM {table_name} LIMIT {BATCH_SIZE} OFFSET {offset};\")\n",
    "        rows = sqlite_cursor.fetchall()\n",
    "        if not rows:\n",
    "            break  # No more rows to fetch\n",
    "\n",
    "        placeholders = \", \".join([\"%s\"] * len(column_names))\n",
    "        insert_query = f\"INSERT INTO {table_name} ({', '.join(column_names)}) VALUES ({placeholders})\"\n",
    "        \n",
    "        execute_batch(pg_cursor, insert_query, rows, page_size=1000)\n",
    "        pg_conn.commit()  # Commit after every batch\n",
    "        \n",
    "        offset += BATCH_SIZE\n",
    "        print(f\"âœ… Inserted {offset}/{total_rows} rows into {table_name}\")\n",
    "\n",
    "    print(f\"âœ… Migration complete for table: {table_name}\")\n",
    "\n",
    "# Close connections\n",
    "pg_cursor.close()\n",
    "pg_conn.close()\n",
    "sqlite_cursor.close()\n",
    "sqlite_conn.close()\n",
    "\n",
    "print(\"ðŸŽ‰ Migration Completed Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
